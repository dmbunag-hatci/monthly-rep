{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a32869da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IMPORTANT CHECK:\n",
      "This script is intended to run on workbooks where all formulas have been\n",
      "replaced by VALUES (copy + paste by values) to avoid breaking references.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please enter the folder path containing the 3 workbooks (files whose names contain '3M', '12WM', and '36WM').\n",
      "\n",
      "Using input folder: C:\\Users\\R103321\\OneDrive - hatci.com\\Desktop\\translate_files\n",
      "Outputs will be written to: C:\\Users\\R103321\\Projects\\monthly-rep\\outputs\n",
      "\n",
      "Searching for workbooks in: C:\\Users\\R103321\\OneDrive - hatci.com\\Desktop\\translate_files\n",
      "Found the following .xlsx files:\n",
      "  - 2025.12-12WM-Full_Update.xlsx\n",
      "  - ★ 3M 26.1월 실적.xlsx\n",
      "  - ★2601월 36WM - 260203 실적 (배포용).xlsx\n",
      "\n",
      "Tag -> matched files:\n",
      "  For tag '3M': OK -> ★ 3M 26.1월 실적.xlsx\n",
      "  For tag '12WM': OK -> 2025.12-12WM-Full_Update.xlsx\n",
      "  For tag '36WM': OK -> ★2601월 36WM - 260203 실적 (배포용).xlsx\n",
      "\n",
      "Workbook mapping (final):\n",
      "  3M -> ★ 3M 26.1월 실적.xlsx\n",
      "  12WM -> 2025.12-12WM-Full_Update.xlsx\n",
      "  36WM -> ★2601월 36WM - 260203 실적 (배포용).xlsx\n",
      "\n",
      "⏳ Processing 3M workbook: ★ 3M 26.1월 실적.xlsx\n",
      "✅ Finished processing 3M.\n",
      "  Output workbook: 3M-full_update-translated.xlsx\n",
      "  Scanned text cells (non-formula): 19741\n",
      "  Changed cells: 8446\n",
      "\n",
      "⏳ Processing 12WM workbook: 2025.12-12WM-Full_Update.xlsx\n",
      "✅ Finished processing 12WM.\n",
      "  Output workbook: 12WM-full_update-translated.xlsx\n",
      "  Scanned text cells (non-formula): 126840\n",
      "  Changed cells: 113393\n",
      "\n",
      "⏳ Processing 36WM workbook: ★2601월 36WM - 260203 실적 (배포용).xlsx\n",
      "✅ Finished processing 36WM.\n",
      "  Output workbook: 36WM-full_update-translated.xlsx\n",
      "  Scanned text cells (non-formula): 131894\n",
      "  Changed cells: 26013\n",
      "\n",
      "=== All workbooks processed ===\n",
      "Total scanned text cells (non-formula): 278475\n",
      "Total changed cells: 147852\n",
      "Missing unique Hangul items across all workbooks: 1 -> missing_items.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Translate Excel SHEET CONTENTS (cell text) using a user-provided map.json.\n",
    "\n",
    "- Asks user:\n",
    "  1) Did you copy + paste by values in all sheets within all workbooks?\n",
    "  2) Folder path containing the 3M / 12WM / 36WM workbooks.\n",
    "\n",
    "- Does NOT rename existing sheets\n",
    "- Adds a new first sheet \"Sheet Name Trans.\" with:\n",
    "  * Original sheet names\n",
    "  * English translations of sheet names (using map.json)\n",
    "- \"Sheet Name Trans.\" is NOT scanned/translated like other sheets.\n",
    "\n",
    "- Does NOT modify formulas (skips them by default)\n",
    "- Does NOT overwrite map.json (read-only)\n",
    "- Uses strict Hangul-with-spaces phrases + remaining Hangul runs\n",
    "- Writes:\n",
    "  * 3M-full_update-translated.xlsx\n",
    "  * 12WM-full_update-translated.xlsx\n",
    "  * 36WM-full_update-translated.xlsx\n",
    "  * missing_items.csv (Hangul detected but not present in map.json)\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import json\n",
    "import collections\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "\n",
    "# Tags we expect in filenames to identify each workbook\n",
    "WORKBOOK_TAGS = [\"3M\", \"12WM\", \"36WM\"]\n",
    "\n",
    "# Use your cleaned map file here (or rename it to map.json)\n",
    "MAP_JSON = \"map.json\"\n",
    "\n",
    "# Name for the missing items CSV (will be written into outputs/ folder)\n",
    "MISSING_CSV = \"missing_items.csv\"\n",
    "\n",
    "SKIP_FORMULAS = True\n",
    "APPLY_SPACE_NORMALIZATION = True\n",
    "\n",
    "SHEET_NAME_TRANSLATION_TITLE = \"Sheet Name Trans.\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# HANGUL DETECTION / EXTRACTION\n",
    "# -----------------------------\n",
    "HANGUL_CHAR_RE = re.compile(r\"[\\uac00-\\ud7a3]\")\n",
    "HANGUL_PHRASE_RE = re.compile(r\"[\\uac00-\\ud7a3]+(?:\\s+[\\uac00-\\ud7a3]+)+\")\n",
    "HANGUL_RUN_RE = re.compile(r\"[\\uac00-\\ud7a3]+\")\n",
    "\n",
    "\n",
    "def has_hangul(s: str) -> bool:\n",
    "    return isinstance(s, str) and bool(HANGUL_CHAR_RE.search(s))\n",
    "\n",
    "\n",
    "def extract_phrases_and_runs_strict(text: str) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Extract:\n",
    "      - phrases: Hangul words separated by spaces\n",
    "      - runs: remaining contiguous Hangul sequences after removing phrases\n",
    "    \"\"\"\n",
    "    phrases = HANGUL_PHRASE_RE.findall(text)\n",
    "    remainder = text\n",
    "    for p in phrases:\n",
    "        remainder = remainder.replace(p, \" \")\n",
    "    runs = HANGUL_RUN_RE.findall(remainder)\n",
    "    return phrases, runs\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# OPTIONAL SPACE NORMALIZATION\n",
    "# -----------------------------\n",
    "def normalize_spaces(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # ) followed by alnum: add space\n",
    "    text = re.sub(r\"\\)(?=[A-Za-z0-9])\", \") \", text)\n",
    "    # Alpha right next to Hangul (both directions): add space\n",
    "    text = re.sub(r\"([A-Za-z])([\\uac00-\\ud7a3])\", r\"\\1 \\2\", text)\n",
    "    text = re.sub(r\"([\\uac00-\\ud7a3])([A-Za-z])\", r\"\\1 \\2\", text)\n",
    "    # Hangul right before \"Plant\" (with optional digits): add space\n",
    "    text = re.sub(r\"([\\uac00-\\ud7a3])(\\d*Plant)\", r\"\\1 \\2\", text)\n",
    "    # Collapse multiple spaces\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# TOKEN PROTECTION\n",
    "# -----------------------------\n",
    "# Protect codes/ids/numbers; protect parentheses only if NO Hangul inside.\n",
    "TOKEN_PATTERNS = [\n",
    "    r\"\\[[^\\]]+\\]\",                           # [ABC123]\n",
    "    r\"\\b[A-Z]{1,5}\\d{0,5}\\b\",                # codes like ABC12\n",
    "    r\"\\b\\d+(?:\\.\\d+)?(?:E[-+]\\d+)?\\b\",       # numbers, floats, scientific notation\n",
    "    r\"\\((?!.*[\\uac00-\\ud7a3])[^\\)]*\\)\",      # (...) with no Hangul inside\n",
    "]\n",
    "TOKEN_RE = re.compile(\"|\".join(f\"({p})\" for p in TOKEN_PATTERNS))\n",
    "\n",
    "\n",
    "def protect_tokens(text: str) -> Tuple[str, List[str]]:\n",
    "    tokens: List[str] = []\n",
    "\n",
    "    def repl(m):\n",
    "        tokens.append(m.group(0))\n",
    "        return f\"__TOK{len(tokens)-1}__\"\n",
    "\n",
    "    return TOKEN_RE.sub(repl, text), tokens\n",
    "\n",
    "\n",
    "def restore_tokens(text: str, tokens: List[str]) -> str:\n",
    "    for i, tok in enumerate(tokens):\n",
    "        text = text.replace(f\"__TOK{i}__\", tok)\n",
    "    return text\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# MAP LOADING (READ-ONLY)\n",
    "# -----------------------------\n",
    "def load_fragments_map(path: str) -> Dict[str, str]:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Map file not found: {p.resolve()}\")\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    fragments = data.get(\"fragments\", {})\n",
    "    if not isinstance(fragments, dict):\n",
    "        raise ValueError('Map must look like: {\"fragments\": { ... }}')\n",
    "    return fragments\n",
    "\n",
    "\n",
    "def build_pairs(fragments: Dict[str, str]) -> List[Tuple[str, str]]:\n",
    "    # Sort keys longest-first to avoid partial-replacement collisions\n",
    "    keys = sorted(fragments.keys(), key=len, reverse=True)\n",
    "    return [(k, fragments[k]) for k in keys]\n",
    "\n",
    "\n",
    "def translate_text_with_map(text: str, pairs: List[Tuple[str, str]]) -> str:\n",
    "    masked, toks = protect_tokens(text)\n",
    "    out = masked\n",
    "    for k, v in pairs:\n",
    "        out = out.replace(k, v)\n",
    "    out = restore_tokens(out, toks)\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# WORKBOOK DISCOVERY\n",
    "# -----------------------------\n",
    "def find_workbooks_by_tag(folder: Path, tags: List[str]) -> Optional[Dict[str, Path]]:\n",
    "    \"\"\"\n",
    "    Scan folder for .xlsx files and map each tag (e.g. '3M') to exactly one file\n",
    "    whose name contains that tag.\n",
    "\n",
    "    Returns:\n",
    "        dict[tag -> Path] if successful, otherwise None (and prints errors).\n",
    "    \"\"\"\n",
    "    if not folder.is_dir():\n",
    "        print(f\"\\nERROR: Input folder not found: {folder.resolve()}\")\n",
    "        return None\n",
    "\n",
    "    all_xlsx = [p for p in folder.glob(\"*.xlsx\") if not p.name.startswith(\"~$\")]\n",
    "\n",
    "    print(\"\\nSearching for workbooks in:\", folder.resolve())\n",
    "    if not all_xlsx:\n",
    "        print(\"No .xlsx files found in this folder.\")\n",
    "    else:\n",
    "        print(\"Found the following .xlsx files:\")\n",
    "        for p in all_xlsx:\n",
    "            print(f\"  - {p.name}\")\n",
    "\n",
    "    mapping: Dict[str, Path] = {}\n",
    "    errors: List[str] = []\n",
    "\n",
    "    print(\"\\nTag -> matched files:\")\n",
    "    for tag in tags:\n",
    "        matches = [p for p in all_xlsx if tag in p.name]\n",
    "\n",
    "        if len(matches) == 0:\n",
    "            msg = (\n",
    "                f\"  For tag '{tag}': expected 1 file, found 0. \"\n",
    "                f\"No filenames containing '{tag}'.\"\n",
    "            )\n",
    "            print(msg)\n",
    "            errors.append(msg)\n",
    "        elif len(matches) == 1:\n",
    "            print(f\"  For tag '{tag}': OK -> {matches[0].name}\")\n",
    "            mapping[tag] = matches[0]\n",
    "        else:\n",
    "            names = \", \".join(m.name for m in matches)\n",
    "            msg = (\n",
    "                f\"  For tag '{tag}': expected 1 file, found {len(matches)}: {names}\"\n",
    "            )\n",
    "            print(msg)\n",
    "            errors.append(msg)\n",
    "\n",
    "    if errors:\n",
    "        print(\"\\nERROR: Workbook detection failed.\")\n",
    "        print(\"Details:\")\n",
    "        for e in errors:\n",
    "            print(\" -\", e)\n",
    "        print(\n",
    "            \"\\nPlease ensure there is exactly one file containing each of \"\n",
    "            f\"{', '.join(tags)} in the selected folder, then re-run the script.\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    print(\"\\nWorkbook mapping (final):\")\n",
    "    for tag, path in mapping.items():\n",
    "        print(f\"  {tag} -> {path.name}\")\n",
    "\n",
    "    return mapping\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# SHEET NAME TRANSLATION SHEET\n",
    "# -----------------------------\n",
    "def add_sheet_name_translation_sheet(\n",
    "    wb,\n",
    "    input_path: Path,\n",
    "    fragments: Dict[str, str],\n",
    "    pairs: List[Tuple[str, str]],\n",
    "    missing_counts: collections.Counter,\n",
    "    missing_example: Dict[str, str],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create a new first sheet \"Sheet Name Trans.\" listing:\n",
    "      - Original sheet names\n",
    "      - Translated sheet names\n",
    "\n",
    "    NOTE: This version does NOT contribute sheet-name Hangul\n",
    "    to missing_counts / missing_example. missing_items.csv\n",
    "    now reflects ONLY cell contents.\n",
    "    \"\"\"\n",
    "    # Get original sheet names (before adding the new sheet)\n",
    "    original_sheet_names = list(wb.sheetnames)\n",
    "\n",
    "    # Compute translations for sheet names (no missing-items tracking here)\n",
    "    translations: List[Tuple[str, str]] = []\n",
    "    for sheet_name in original_sheet_names:\n",
    "        original = sheet_name\n",
    "        processed = original.strip()\n",
    "        if APPLY_SPACE_NORMALIZATION:\n",
    "            processed = normalize_spaces(processed)\n",
    "\n",
    "        # Translate sheet name (for display only; we do NOT rename sheets)\n",
    "        translated = translate_text_with_map(processed, pairs)\n",
    "        if APPLY_SPACE_NORMALIZATION:\n",
    "            translated = normalize_spaces(translated)\n",
    "\n",
    "        translations.append((original, translated))\n",
    "\n",
    "    # Create the new sheet at position 0\n",
    "    sheet = wb.create_sheet(title=SHEET_NAME_TRANSLATION_TITLE, index=0)\n",
    "\n",
    "    # Header row\n",
    "    sheet[\"A1\"] = \"Original Sheet Name\"\n",
    "    sheet[\"B1\"] = \"Translated Sheet Name\"\n",
    "\n",
    "    # Data rows\n",
    "    row_idx = 2\n",
    "    for original, translated in translations:\n",
    "        sheet.cell(row=row_idx, column=1, value=original)\n",
    "        sheet.cell(row=row_idx, column=2, value=translated)\n",
    "        row_idx += 1\n",
    "# -----------------------------\n",
    "# MAIN\n",
    "# -----------------------------\n",
    "def main():\n",
    "    # 1. Safety confirmation in terminal\n",
    "    print(\n",
    "        \"\\nIMPORTANT CHECK:\\n\"\n",
    "        \"This script is intended to run on workbooks where all formulas have been\\n\"\n",
    "        \"replaced by VALUES (copy + paste by values) to avoid breaking references.\\n\"\n",
    "    )\n",
    "    answer = input(\n",
    "        \"Did you copy + paste by values in all sheets within all workbooks? [y/N]: \"\n",
    "    ).strip().lower()\n",
    "\n",
    "    if answer not in (\"y\", \"yes\"):\n",
    "        print(\n",
    "            \"\\nAborting: Please create value-only versions of your workbooks first, \"\n",
    "            \"then re-run this script.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # 2. Ask user for folder path\n",
    "    print(\n",
    "        \"\\nPlease enter the folder path containing the 3 workbooks \"\n",
    "        \"(files whose names contain '3M', '12WM', and '36WM').\"\n",
    "    )\n",
    "    folder_input = input(\"Folder path: \").strip()\n",
    "\n",
    "    if not folder_input:\n",
    "        print(\"\\nNo folder path entered. Aborting.\")\n",
    "        return\n",
    "\n",
    "    # Allow user to paste with quotes; strip leading/trailing quotes if present\n",
    "    folder_input = folder_input.strip().strip('\"').strip(\"'\")\n",
    "    input_folder = Path(folder_input)\n",
    "    print(f\"\\nUsing input folder: {input_folder.resolve()}\")\n",
    "\n",
    "    # 3. Resolve script directory and outputs folder\n",
    "    try:\n",
    "        script_dir = Path(__file__).resolve().parent\n",
    "    except NameError:\n",
    "        # Fallback if __file__ is not defined (e.g. in some interactive environments)\n",
    "        script_dir = Path.cwd()\n",
    "\n",
    "    outputs_dir = script_dir / \"outputs\"\n",
    "    outputs_dir.mkdir(exist_ok=True)\n",
    "    print(f\"Outputs will be written to: {outputs_dir.resolve()}\")\n",
    "\n",
    "    # 4. Load translation map (fragments)\n",
    "    fragments = load_fragments_map(MAP_JSON)\n",
    "    pairs = build_pairs(fragments)\n",
    "\n",
    "    # 5. Discover the 3 target workbooks in the input folder\n",
    "    files_by_tag = find_workbooks_by_tag(input_folder, WORKBOOK_TAGS)\n",
    "    if files_by_tag is None:\n",
    "        # Errors already printed; just abort\n",
    "        return\n",
    "\n",
    "    # 6. Global counters for missing items across ALL workbooks\n",
    "    missing_counts = collections.Counter()\n",
    "    missing_example: Dict[str, str] = {}\n",
    "\n",
    "    total_scanned = 0\n",
    "    total_changed = 0\n",
    "\n",
    "    # 7. Process each workbook\n",
    "    for tag, input_path in files_by_tag.items():\n",
    "        print(f\"\\n⏳ Processing {tag} workbook: {input_path.name}\")\n",
    "\n",
    "        wb = load_workbook(input_path, data_only=False)\n",
    "\n",
    "        # 7a. Add \"Sheet Name Trans.\" sheet with sheet-name translations\n",
    "        add_sheet_name_translation_sheet(\n",
    "            wb, input_path, fragments, pairs, missing_counts, missing_example\n",
    "        )\n",
    "\n",
    "        scanned = 0\n",
    "        changed = 0\n",
    "\n",
    "        # 7b. Translate cell contents on all sheets EXCEPT \"Sheet Name Trans.\"\n",
    "        for ws in wb.worksheets:\n",
    "            if ws.title == SHEET_NAME_TRANSLATION_TITLE:\n",
    "                # Skip the translation sheet itself\n",
    "                continue\n",
    "\n",
    "            for row in ws.iter_rows():\n",
    "                for cell in row:\n",
    "                    v = cell.value\n",
    "                    if not isinstance(v, str):\n",
    "                        continue\n",
    "                    if SKIP_FORMULAS and v.startswith(\"=\"):\n",
    "                        continue\n",
    "\n",
    "                    scanned += 1\n",
    "                    text = v.strip()\n",
    "                    if APPLY_SPACE_NORMALIZATION:\n",
    "                        text = normalize_spaces(text)\n",
    "\n",
    "                    if not has_hangul(text):\n",
    "                        # Still write normalized text (e.g. spacing changes) if needed\n",
    "                        if APPLY_SPACE_NORMALIZATION and text != v:\n",
    "                            cell.value = text\n",
    "                        continue\n",
    "\n",
    "                    # Missing Hangul detection for cell contents\n",
    "                    phrases, runs = extract_phrases_and_runs_strict(text)\n",
    "                    for item in phrases + runs:\n",
    "                        if item and item not in fragments:\n",
    "                            missing_counts[item] += 1\n",
    "                            example_key = (\n",
    "                                f\"{input_path.name}:{ws.title}!{cell.coordinate}\"\n",
    "                            )\n",
    "                            missing_example.setdefault(item, example_key)\n",
    "\n",
    "                    # Translation\n",
    "                    out = translate_text_with_map(text, pairs)\n",
    "                    if APPLY_SPACE_NORMALIZATION:\n",
    "                        out = normalize_spaces(out)\n",
    "\n",
    "                    if out != v:\n",
    "                        cell.value = out\n",
    "                        changed += 1\n",
    "\n",
    "        # 7c. Save translated workbook for this tag\n",
    "        output_name = f\"{tag}-full_update-translated.xlsx\"\n",
    "        output_path = outputs_dir / output_name\n",
    "        wb.save(output_path)\n",
    "\n",
    "        print(f\"✅ Finished processing {tag}.\")\n",
    "        print(f\"  Output workbook: {output_path.name}\")\n",
    "        print(f\"  Scanned text cells (non-formula): {scanned}\")\n",
    "        print(f\"  Changed cells: {changed}\")\n",
    "\n",
    "        total_scanned += scanned\n",
    "        total_changed += changed\n",
    "\n",
    "    # 8. Write combined missing_items.csv for all workbooks\n",
    "    df_missing = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"hangul\": k,\n",
    "                \"count\": int(c),\n",
    "                \"example_cell\": missing_example.get(k, \"\"),\n",
    "            }\n",
    "            for k, c in missing_counts.most_common()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    missing_csv_path = outputs_dir / MISSING_CSV\n",
    "    df_missing.to_csv(missing_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(\"\\n=== All workbooks processed ===\")\n",
    "    print(f\"Total scanned text cells (non-formula): {total_scanned}\")\n",
    "    print(f\"Total changed cells: {total_changed}\")\n",
    "    print(\n",
    "        f\"Missing unique Hangul items across all workbooks: {len(missing_counts)} \"\n",
    "        f\"-> {missing_csv_path.name}\"\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43367c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c9c4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c263e64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cfd8e0b",
   "metadata": {},
   "source": [
    "## Data Extraction (In progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54fc511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = r\"C:\\Users\\R103321\\Projects\\monthly-rep\\outputs\\3M-full_update-translated.xlsx\"\n",
    "\n",
    "# Sheet 2: drop the first row, keep row 2 as main header and row 3 as subheader\n",
    "df_sheet2 = pd.read_excel(\n",
    "    path,\n",
    "    sheet_name=2,\n",
    "    header=[0, 1],\n",
    "    skiprows=1,\n",
    "    engine=\"openpyxl\"\n",
    ")\n",
    "\n",
    "# Sheet 3: keep the first row, and use row 1 and row 2 as headers\n",
    "df_sheet3 = pd.read_excel(\n",
    "    path,\n",
    "    sheet_name=3,\n",
    "    header=[0, 1],\n",
    "    engine=\"openpyxl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d17fb034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_level_0</th>\n",
       "      <th colspan=\"6\" halign=\"left\">26 yr</th>\n",
       "      <th colspan=\"3\" halign=\"left\">1 mo</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">11 mo</th>\n",
       "      <th colspan=\"6\" halign=\"left\">12 mo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Target Cases</th>\n",
       "      <th>Actual Cases</th>\n",
       "      <th>Sales Units</th>\n",
       "      <th>3M Target</th>\n",
       "      <th>3M Actual</th>\n",
       "      <th>Achievement Rate</th>\n",
       "      <th>Target Cases</th>\n",
       "      <th>Actual Cases</th>\n",
       "      <th>Sales Units</th>\n",
       "      <th>...</th>\n",
       "      <th>Sales Units</th>\n",
       "      <th>3M Target</th>\n",
       "      <th>3M Actual</th>\n",
       "      <th>Achievement Rate</th>\n",
       "      <th>Target Cases</th>\n",
       "      <th>Actual Cases</th>\n",
       "      <th>Sales Units</th>\n",
       "      <th>3M Target</th>\n",
       "      <th>3M Actual</th>\n",
       "      <th>Achievement Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G</td>\n",
       "      <td>7.041004</td>\n",
       "      <td>2.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>148.231653</td>\n",
       "      <td>42.105263</td>\n",
       "      <td>3.520502</td>\n",
       "      <td>7.041004</td>\n",
       "      <td>2.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0_level_0        26 yr                                       \\\n",
       "            Category Target Cases Actual Cases Sales Units   3M Target   \n",
       "0                  G     7.041004          2.0       475.0  148.231653   \n",
       "\n",
       "                                      1 mo                           ...  \\\n",
       "   3M Actual Achievement Rate Target Cases Actual Cases Sales Units  ...   \n",
       "0  42.105263         3.520502     7.041004          2.0       475.0  ...   \n",
       "\n",
       "        11 mo                                             12 mo               \\\n",
       "  Sales Units 3M Target 3M Actual Achievement Rate Target Cases Actual Cases   \n",
       "0         NaN       NaN       NaN              NaN          NaN          NaN   \n",
       "\n",
       "                                                    \n",
       "  Sales Units 3M Target 3M Actual Achievement Rate  \n",
       "0         NaN       NaN       NaN              NaN  \n",
       "\n",
       "[1 rows x 79 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sheet3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c03c6643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_level_0</th>\n",
       "      <th>Unnamed: 1_level_0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Summary</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Category</th>\n",
       "      <th colspan=\"3\" halign=\"left\">1 mo</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">25Year Cumulative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Domestic</th>\n",
       "      <th>Overseas</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>Overseas</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Warranty Owner</th>\n",
       "      <th>Type</th>\n",
       "      <th>Domestic Cases</th>\n",
       "      <th>Domestic Units</th>\n",
       "      <th>Domestic Target</th>\n",
       "      <th>...</th>\n",
       "      <th>Overseas Cases</th>\n",
       "      <th>Overseas Units</th>\n",
       "      <th>Overseas Target</th>\n",
       "      <th>Overseas Actual</th>\n",
       "      <th>Overseas Achievement Rate</th>\n",
       "      <th>Total Cases</th>\n",
       "      <th>Total Units</th>\n",
       "      <th>Total Target</th>\n",
       "      <th>Total Actual</th>\n",
       "      <th>Total Achievement Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hyundai QA Office Domestic</td>\n",
       "      <td>Hyundai QA Office Overseas</td>\n",
       "      <td>Domestic H</td>\n",
       "      <td>Overseas H</td>\n",
       "      <td>Quality Assurance Division</td>\n",
       "      <td>Hyundai Quality Assurance Office</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>1824</td>\n",
       "      <td>102005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>663</td>\n",
       "      <td>170757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.827105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2487</td>\n",
       "      <td>272762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.17839</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0_level_0          Unnamed: 1_level_0     Summary  \\\n",
       "                     Domestic                    Overseas    Domestic   \n",
       "0  Hyundai QA Office Domestic  Hyundai QA Office Overseas  Domestic H   \n",
       "\n",
       "                                 Category                                    \\\n",
       "     Overseas                 Affiliation                    Warranty Owner   \n",
       "0  Overseas H  Quality Assurance Division  Hyundai Quality Assurance Office   \n",
       "\n",
       "                       1 mo                                 ...  \\\n",
       "        Type Domestic Cases Domestic Units Domestic Target  ...   \n",
       "0  Passenger           1824         102005             NaN  ...   \n",
       "\n",
       "  25Year Cumulative                                                 \\\n",
       "     Overseas Cases Overseas Units Overseas Target Overseas Actual   \n",
       "0               663         170757             NaN       38.827105   \n",
       "\n",
       "                                                                               \\\n",
       "  Overseas Achievement Rate Total Cases Total Units Total Target Total Actual   \n",
       "0                       NaN        2487      272762          NaN     91.17839   \n",
       "\n",
       "                          \n",
       "  Total Achievement Rate  \n",
       "0                    NaN  \n",
       "\n",
       "[1 rows x 202 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sheet2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140b7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729c0194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "028b6998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R103321\\AppData\\Local\\Temp\\ipykernel_8808\\678262727.py:45: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_small.applymap(is_missing).all().all()\n",
      "C:\\Users\\R103321\\AppData\\Local\\Temp\\ipykernel_8808\\678262727.py:45: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_small.applymap(is_missing).all().all()\n",
      "C:\\Users\\R103321\\AppData\\Local\\Temp\\ipykernel_8808\\678262727.py:45: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_small.applymap(is_missing).all().all()\n",
      "C:\\Users\\R103321\\AppData\\Local\\Temp\\ipykernel_8808\\678262727.py:45: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_small.applymap(is_missing).all().all()\n",
      "C:\\Users\\R103321\\AppData\\Local\\Temp\\ipykernel_8808\\678262727.py:45: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_small.applymap(is_missing).all().all()\n",
      "C:\\Users\\R103321\\AppData\\Local\\Temp\\ipykernel_8808\\678262727.py:45: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_small.applymap(is_missing).all().all()\n",
      "C:\\Users\\R103321\\AppData\\Local\\Temp\\ipykernel_8808\\678262727.py:45: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_small.applymap(is_missing).all().all()\n",
      "C:\\Users\\R103321\\AppData\\Local\\Temp\\ipykernel_8808\\678262727.py:45: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_small.applymap(is_missing).all().all()\n",
      "C:\\Users\\R103321\\AppData\\Local\\Temp\\ipykernel_8808\\678262727.py:45: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_small.applymap(is_missing).all().all()\n",
      "C:\\Users\\R103321\\AppData\\Local\\Temp\\ipykernel_8808\\678262727.py:45: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_small.applymap(is_missing).all().all()\n",
      "C:\\Users\\R103321\\AppData\\Local\\Temp\\ipykernel_8808\\678262727.py:45: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_small.applymap(is_missing).all().all()\n",
      "C:\\Users\\R103321\\AppData\\Local\\Temp\\ipykernel_8808\\678262727.py:45: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_small.applymap(is_missing).all().all()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th colspan=\"3\" halign=\"left\">`25.1M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th>3M Target</th>\n",
       "      <th>3M Actual</th>\n",
       "      <th>Achievement Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Genesis</th>\n",
       "      <td>391</td>\n",
       "      <td>331</td>\n",
       "      <td>1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyundai</th>\n",
       "      <td>311</td>\n",
       "      <td>373</td>\n",
       "      <td>83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kia</th>\n",
       "      <td>228</td>\n",
       "      <td>223</td>\n",
       "      <td>1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAQC</th>\n",
       "      <td>273</td>\n",
       "      <td>295</td>\n",
       "      <td>93%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Month       `25.1M                           \n",
       "Metric   3M Target 3M Actual Achievement Rate\n",
       "Category                                     \n",
       "Genesis        391       331               1%\n",
       "Hyundai        311       373              83%\n",
       "Kia            228       223               1%\n",
       "NAQC           273       295              93%"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_3m_metrics_by_sequence(\n",
    "    df_sheet3: pd.DataFrame,\n",
    "    months_max: int = 12,\n",
    "    month_suffix: str = \" mo\",\n",
    "    subcol_names: list[str] | None = None,\n",
    "    category_col: tuple = (\"Unnamed: 0_level_0\", \"Category\"),\n",
    "    sequence: list[str] | None = None,\n",
    "    rename_map: dict | None = None,\n",
    "    extra_main_col: str = \"25 yr\",\n",
    ") -> pd.DataFrame:\n",
    "    if sequence is None:\n",
    "        sequence = [\"G\", \"H\", \"K\", \"North America\"]\n",
    "\n",
    "    if rename_map is None:\n",
    "        rename_map = {\n",
    "            \"G\": \"Genesis\",\n",
    "            \"H\": \"Hyundai\",\n",
    "            \"K\": \"Kia\",\n",
    "            \"North America\": \"NAQC\",\n",
    "        }\n",
    "\n",
    "    if subcol_names is None:\n",
    "        subcol_names = [\"3M Target\", \"3M Actual\", \"Achievement Rate\"]\n",
    "\n",
    "    if not isinstance(df_sheet3.columns, pd.MultiIndex) or df_sheet3.columns.nlevels < 2:\n",
    "        raise ValueError(\"df_sheet3 must have MultiIndex columns with 2 levels\")\n",
    "\n",
    "    if category_col not in df_sheet3.columns:\n",
    "        raise KeyError(f\"Category column not found: {category_col}\")\n",
    "\n",
    "    def is_missing(x) -> bool:\n",
    "        if x is None or pd.isna(x):\n",
    "            return True\n",
    "        if isinstance(x, str):\n",
    "            t = x.strip()\n",
    "            if t == \"\":\n",
    "                return True\n",
    "            if t.upper() in {\"<NA>\", \"NA\", \"N/A\", \"NONE\", \"NULL\", \"NAN\"}:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def block_all_missing(df_small: pd.DataFrame) -> bool:\n",
    "        return df_small.applymap(is_missing).all().all()\n",
    "\n",
    "    def parse_int_series(s: pd.Series) -> pd.Series:\n",
    "        cleaned = s.astype(str).str.replace(\",\", \"\", regex=False).str.strip()\n",
    "        cleaned = cleaned.replace({\"<NA>\": pd.NA, \"\": pd.NA, \"NA\": pd.NA, \"N/A\": pd.NA})\n",
    "        return pd.to_numeric(cleaned, errors=\"coerce\").round(0).astype(\"Int64\")\n",
    "\n",
    "    def parse_pct_value(x):\n",
    "        if is_missing(x):\n",
    "            return pd.NA\n",
    "        if isinstance(x, str):\n",
    "            t = x.strip().replace(\",\", \"\")\n",
    "            if t.endswith(\"%\"):\n",
    "                t = t[:-1].strip()\n",
    "            try:\n",
    "                val = float(t)\n",
    "            except Exception:\n",
    "                return pd.NA\n",
    "        else:\n",
    "            try:\n",
    "                val = float(x)\n",
    "            except Exception:\n",
    "                return pd.NA\n",
    "\n",
    "        if abs(val) <= 1.0:\n",
    "            val *= 100.0\n",
    "\n",
    "        return f\"{int(round(val))}%\"\n",
    "\n",
    "    cat = df_sheet3[category_col].astype(str).str.strip().tolist()\n",
    "\n",
    "    seq_len = len(sequence)\n",
    "    start_pos = None\n",
    "    for i in range(len(cat) - seq_len + 1):\n",
    "        if cat[i : i + seq_len] == sequence:\n",
    "            start_pos = i\n",
    "            break\n",
    "\n",
    "    if start_pos is None:\n",
    "        return pd.DataFrame(index=pd.Index([], name=\"Category\"))\n",
    "\n",
    "    block = df_sheet3.iloc[start_pos : start_pos + seq_len, :]\n",
    "\n",
    "    cols_to_use: list[tuple] = []\n",
    "    out_col_tuples: list[tuple] = []\n",
    "\n",
    "    for mnum in range(1, months_max + 1):\n",
    "        main = f\"{mnum}{month_suffix}\"\n",
    "        month_label = f\"`25.{mnum}M\"\n",
    "\n",
    "        candidate_keys = [(main, sub) for sub in subcol_names if (main, sub) in df_sheet3.columns]\n",
    "        if not candidate_keys:\n",
    "            continue\n",
    "\n",
    "        month_block = block.loc[:, candidate_keys]\n",
    "        if block_all_missing(month_block):\n",
    "            continue\n",
    "\n",
    "        for sub in subcol_names:\n",
    "            key = (main, sub)\n",
    "            if key in df_sheet3.columns:\n",
    "                cols_to_use.append(key)\n",
    "                out_col_tuples.append((month_label, sub))\n",
    "\n",
    "    extra_keys = [(extra_main_col, sub) for sub in subcol_names if (extra_main_col, sub) in df_sheet3.columns]\n",
    "    if extra_keys:\n",
    "        extra_block = block.loc[:, extra_keys]\n",
    "        if not block_all_missing(extra_block):\n",
    "            for sub in subcol_names:\n",
    "                key = (extra_main_col, sub)\n",
    "                if key in df_sheet3.columns:\n",
    "                    cols_to_use.append(key)\n",
    "                    out_col_tuples.append((extra_main_col, sub))\n",
    "\n",
    "    if not cols_to_use:\n",
    "        renamed_index = [rename_map.get(x, x) for x in sequence]\n",
    "        return pd.DataFrame(index=pd.Index(renamed_index, name=\"Category\"))\n",
    "\n",
    "    out = block.loc[:, cols_to_use].copy()\n",
    "\n",
    "    out.index = sequence\n",
    "    out.index = out.index.map(lambda x: rename_map.get(x, x))\n",
    "    out.index.name = \"Category\"\n",
    "\n",
    "    out.columns = pd.MultiIndex.from_tuples(out_col_tuples, names=[\"Month\", \"Metric\"])\n",
    "\n",
    "    for col in out.columns:\n",
    "        metric = col[1]\n",
    "        if metric == \"Achievement Rate\":\n",
    "            out[col] = out[col].map(parse_pct_value).astype(\"string\")\n",
    "        else:\n",
    "            out[col] = parse_int_series(out[col])\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "result_3m_actual = extract_3m_metrics_by_sequence(df_sheet3, extra_main_col=\"25 yr\")\n",
    "result_3m_actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd88134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac218e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7316a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domestic Target</th>\n",
       "      <th>Domestic Actual</th>\n",
       "      <th>Domestic Achievement Rate</th>\n",
       "      <th>Overseas Target</th>\n",
       "      <th>Overseas Actual</th>\n",
       "      <th>Overseas Achievement Rate</th>\n",
       "      <th>Total Target</th>\n",
       "      <th>Total Actual</th>\n",
       "      <th>Total Achievement Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1 mo</th>\n",
       "      <td>271.57585</td>\n",
       "      <td>271.720929</td>\n",
       "      <td>0.999466</td>\n",
       "      <td>85.848717</td>\n",
       "      <td>82.742529</td>\n",
       "      <td>1.03754</td>\n",
       "      <td>168.616481</td>\n",
       "      <td>166.959194</td>\n",
       "      <td>1.009926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 mo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 mo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 mo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 mo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 mo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 mo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 mo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 mo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 mo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11 mo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 mo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25Year Cumulative</th>\n",
       "      <td>NaN</td>\n",
       "      <td>271.720929</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.742529</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.959194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Domestic Target Domestic Actual Domestic Achievement Rate  \\\n",
       "Month                                                                         \n",
       "1 mo                    271.57585      271.720929                  0.999466   \n",
       "2 mo                          NaN               0                       NaN   \n",
       "3 mo                          NaN               0                       NaN   \n",
       "4 mo                          NaN               0                       NaN   \n",
       "5 mo                          NaN               0                       NaN   \n",
       "6 mo                          NaN               0                       NaN   \n",
       "7 mo                          NaN               0                       NaN   \n",
       "8 mo                          NaN               0                       NaN   \n",
       "9 mo                          NaN               0                       NaN   \n",
       "10 mo                         NaN               0                       NaN   \n",
       "11 mo                         NaN               0                       NaN   \n",
       "12 mo                         NaN               0                       NaN   \n",
       "25Year Cumulative             NaN      271.720929                         0   \n",
       "\n",
       "                  Overseas Target Overseas Actual Overseas Achievement Rate  \\\n",
       "Month                                                                         \n",
       "1 mo                    85.848717       82.742529                   1.03754   \n",
       "2 mo                          NaN               0                       NaN   \n",
       "3 mo                          NaN               0                       NaN   \n",
       "4 mo                          NaN               0                       NaN   \n",
       "5 mo                          NaN               0                       NaN   \n",
       "6 mo                          NaN               0                       NaN   \n",
       "7 mo                          NaN               0                       NaN   \n",
       "8 mo                          NaN               0                       NaN   \n",
       "9 mo                          NaN               0                       NaN   \n",
       "10 mo                         NaN               0                       NaN   \n",
       "11 mo                         NaN               0                       NaN   \n",
       "12 mo                         NaN               0                       NaN   \n",
       "25Year Cumulative             NaN       82.742529                         0   \n",
       "\n",
       "                  Total Target Total Actual Total Achievement Rate  \n",
       "Month                                                               \n",
       "1 mo                168.616481   166.959194               1.009926  \n",
       "2 mo                       NaN            0                    NaN  \n",
       "3 mo                       NaN            0                    NaN  \n",
       "4 mo                       NaN            0                    NaN  \n",
       "5 mo                       NaN            0                    NaN  \n",
       "6 mo                       NaN            0                    NaN  \n",
       "7 mo                       NaN            0                    NaN  \n",
       "8 mo                       NaN            0                    NaN  \n",
       "9 mo                       NaN            0                    NaN  \n",
       "10 mo                      NaN            0                    NaN  \n",
       "11 mo                      NaN            0                    NaN  \n",
       "12 mo                      NaN            0                    NaN  \n",
       "25Year Cumulative          NaN   166.959194                      0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_month_table(\n",
    "    df: pd.DataFrame,\n",
    "    row_pos: int = 19,\n",
    "    months_max: int = 12,\n",
    "    month_suffix: str = \" mo\",\n",
    "    subcols: list[str] | None = None,\n",
    "    extra_main_col: str = \"25Year Cumulative\",\n",
    ") -> pd.DataFrame:\n",
    "    if subcols is None:\n",
    "        subcols = [\n",
    "            \"Domestic Target\",\n",
    "            \"Domestic Actual\",\n",
    "            \"Domestic Achievement Rate\",\n",
    "            \"Overseas Target\",\n",
    "            \"Overseas Actual\",\n",
    "            \"Overseas Achievement Rate\",\n",
    "            \"Total Target\",\n",
    "            \"Total Actual\",\n",
    "            \"Total Achievement Rate\",\n",
    "        ]\n",
    "\n",
    "    if not isinstance(df.columns, pd.MultiIndex) or df.columns.nlevels < 2:\n",
    "        raise ValueError(\"df.columns must be a MultiIndex with at least 2 levels\")\n",
    "\n",
    "    level0 = df.columns.get_level_values(0)\n",
    "    available_main = set(level0)\n",
    "\n",
    "    month_list = [f\"{i}{month_suffix}\" for i in range(1, months_max + 1)]\n",
    "\n",
    "    mains_to_use = []\n",
    "    for m in month_list:\n",
    "        if m in available_main:\n",
    "            mains_to_use.append(m)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if extra_main_col in available_main:\n",
    "        mains_to_use.append(extra_main_col)\n",
    "\n",
    "    if not mains_to_use:\n",
    "        return pd.DataFrame(index=pd.Index([], name=\"Month\"), columns=subcols)\n",
    "\n",
    "    row_series = df.iloc[row_pos]\n",
    "\n",
    "    table = row_series.unstack(level=0).T\n",
    "\n",
    "    table = table.reindex(index=mains_to_use, columns=subcols)\n",
    "\n",
    "    table.index.name = \"Month\"\n",
    "    return table\n",
    "\n",
    "\n",
    "result = extract_month_table(df_sheet2, row_pos=16, extra_main_col=\"25Year Cumulative\")\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
